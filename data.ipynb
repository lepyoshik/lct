{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import easyocr\n",
    "import cv2\n",
    "import subprocess\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data = pd.read_csv(\"yappy_hackaton_2024_400k.csv\")",
   "id": "fd763d1575f326a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.head(100)",
   "id": "29632ef3eb4d07c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.info()",
   "id": "aa6552d66a6eecf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def download_video(url, filename):\n",
    "    response = requests.get(url)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)"
   ],
   "id": "2833fa196524e5e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def trim_video(input_path, output_path, duration=15):\n",
    "    command = f'ffmpeg -i {input_path} -t {duration} -c copy {output_path} -y'\n",
    "    with open(os.devnull, 'w') as fnull:\n",
    "        subprocess.call(command, shell=True, stdout=fnull, stderr=fnull)"
   ],
   "id": "58638f2c0b521ebc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clear_string(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = re.sub(r'[^a-zA-Zа-яА-Я0-9]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip().lower()"
   ],
   "id": "f37d6553b09df179",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sentence_transformer = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')",
   "id": "e362c37401055938",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_embedding(text):\n",
    "    return sentence_transformer.encode(text)"
   ],
   "id": "9c6a061482093142",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "reader = easyocr.Reader(['ru', 'en'])",
   "id": "2b47110bc636e2fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def ocr_from_video(video_path, target_second=1):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    target_frame = int(fps * target_second)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        texts = reader.readtext(frame, detail=0, paragraph=True)\n",
    "    else:\n",
    "        texts = []\n",
    "        print('Something went wrong (ocr_from_video): cannot read video frame')\n",
    "    cap.release()\n",
    "    text = ' '.join(texts)\n",
    "    return clear_string(text)"
   ],
   "id": "1e5d2594cdad060d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = 'openai/whisper-large-v3'\n",
    "\n",
    "speech_model = AutoModelForSpeechSeq2Seq.from_pretrained(model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True)\n",
    "speech_model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "speech_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=speech_model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ],
   "id": "b29109d1eedb60c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def speech_to_text(video_path):\n",
    "    audio_path = 'temp_audio.mp3'\n",
    "    command = f\"ffmpeg -i {video_path} -q:a 0 -map a {audio_path} -y\"\n",
    "    with open(os.devnull, 'w') as fnull:\n",
    "        subprocess.call(command, shell=True, stdout=fnull, stderr=fnull)\n",
    "    \n",
    "    text = speech_pipe(audio_path)['text']\n",
    "    return clear_string(text)"
   ],
   "id": "3db888a6342184f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "caption_pipe = pipeline('image-to-text', model='nlpconnect/vit-gpt2-image-captioning')",
   "id": "b22cf8e2b78fc117",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def frame_to_pil(frame):\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(rgb_frame)\n",
    "    return pil_image"
   ],
   "id": "ac9ca787df8d1d7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def image_caption(video_path, target_second=1):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    target_frame = int(fps * target_second)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        text = caption_pipe(frame_to_pil(frame))[0]['generated_text']\n",
    "    else:\n",
    "        text = ''\n",
    "    cap.release()\n",
    "    return clear_string(text)"
   ],
   "id": "5c3cb88e3ca4ed25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_embeddings(row):\n",
    "    link = row['link']\n",
    "    description = row['description']\n",
    "    \n",
    "    video_filename = 'temp_video.mp4'\n",
    "    trimmed_video_filename = 'trimmed_video.mp4'\n",
    "    download_video(link, video_filename)\n",
    "    trim_video(video_filename, trimmed_video_filename)\n",
    "    \n",
    "    clean_description = clear_string(description)\n",
    "    clean_description_embed = get_embedding(clean_description)\n",
    "    \n",
    "    video_text = ocr_from_video(trimmed_video_filename)\n",
    "    video_text_embed = get_embedding(video_text)\n",
    "    \n",
    "    speech_text = speech_to_text(trimmed_video_filename)\n",
    "    speech_text_embed = get_embedding(speech_text)\n",
    "    \n",
    "    caption_text = image_caption(trimmed_video_filename)\n",
    "    caption_text_embed = get_embedding(caption_text)\n",
    "    \n",
    "    return clean_description_embed, video_text_embed, speech_text_embed, caption_text_embed"
   ],
   "id": "b100f3ce571627f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embedding_list = []\n",
    "\n",
    "for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "    embeddings = extract_embeddings(row)\n",
    "    embedding_list.append(embeddings)\n",
    "\n",
    "os.remove('temp_video.mp4')\n",
    "os.remove('trimmed_video.mp4')\n",
    "os.remove('temp_audio.mp3')\n",
    "\n",
    "embedding_tensor = torch.stack([torch.cat(embeddings) for embeddings in embedding_list])\n",
    "torch.save(embedding_tensor, 'yappy_tensor.pt')"
   ],
   "id": "b5d3c0c7773401f8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
